TARGET AUDIENCE

Several reviewers asked who the intended users of this tool are and when the
use case is compelling.  The technology is aimed at programmers, and the
central idea is to exploit something that most programmers know well
(regular expressions) to help them write significant programs in a language
that they do not know well (lenses).

Several reviewers wondered whether regular expressions were really necessary
at all and whether we could get away without requiring them.  One of the
reasons we feel our work is valuable is that it illustrates an important
practical tradeoff: by providing data formats, we can infer transformations
over significantly more sophisticated string data types than related systems
which do not use such information.  For instance, FlashFill cannot infer
nested iterations.  17 of our benchmarks have nested iterations and the
deepest nesting structure involved 4 levels of nesting.  As another example,
FlashExtract does not have unions, but it can represent them indirectly by
using options.  Still, in our tests (e.g. on the BibTeX data source),
FlashExtract could not infer transformations between string data types that
contain unions.  By the way, both FlashExtract and FlashFill are wonderful
systems, but they are optimized for other problems.  Our work demonstrates
the tradeoff between designs.  We will make this point more clearly in a
revised version of the paper, and in particular we will quantify the number
of benchmarks that we handle that cannot be handled by other string
synthesis systems.

Several reviewers wondered whether lenses really were tricky to write
and suggested we show a concrete example (thank you -- we should
have).  The following lens translates between idealized BibTeX and
EndNote author formats (it was auto-generated by our tool):

  let bibtex_to_endnote_au
    : (lens in BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS) =
    del "author={"
      . ins "au - "
      . lens_swap (NAME . del ",") (lens_swap WSP NAME)* 
      . (del " and "
           . ins "\n au - "
           . lens_swap (NAME . del ",") (lens_swap WSP NAME)* )* 
      . del "}" 

Writing this lens from scratch is quite tricky and fiddly.  The
trickiest part is the nested swaps, which are fiddly to think about
and get right.  We would also argue that the cognitive model overall
is tricky and quite different from what many programmers are used to
--- one has to think in two directions at once.  Importantly, this is
an incredibly simple example -- Augeas and Boomerang users regularly
work with lenses significantly larger than this.  For example,
Boomerang's full version of an idealized BibTeX converter is over 300
lines of code, and all but 4 of the Augeas programs we studied were
over 50 lines of code, with 4 over 100 lines of code.

FORMALIZATION

A second major concern was the lack of a formal treatment of our
implementation, in particular the function RigidSynth.

In earlier drafts, we actually had a formal description of this
algorithm, but we (regrettably) removed it to get under the page limit
and inadvertently removed it from the extended version at the same
time.  We will reinstate the full treatment in the extended report and
find a good way to summarize it in the final paper.

The formal description is not very complex, but takes a good amount of
space to complete.  The formal description of RigidSynth first
describes an ordering on atoms, sequences, and DNF regular
expressions.  Next, this ordering is used to define a normalization
procedure for DNF regular expressions.  Finally, a procedure for
"zipping" two DNF regular expressions together is provided.  If these
two DNF regular expressions can be zipped, then there is a lens
between them.  A transformation from zipped DNF regular expressions
and the permutations that normalize them is then provided. These
formalizations are not very complex, but they take up a lot of space.

EVALUATION

A third area of concern was our evaluation, specifically the lack of
comparisons with other tools or a quantitative evaluation of the heuristics
we chose in searching for lenses.

Above, we discussed the fact that there are fundamental differences between
the kinds of transformations our tool can perform and the kinds of
transformations tools such as FlashFill and FlashExtract can perform.
We can quantify the set of benchmarks that each tool can process (at least
in one direction).

We agree that quantifying the impact of each heuristic would strengthen the
paper.  We plan to instrument our implementation to gather data on the
effectiveness of each heuristic individually.

Anecdotally, we invented each of these heuristics when more naive approaches
failed.  For example, reviewer D asks whether we "guess an arbitrary regular
expression to deal with composition."  Actually, our first attempt at this
problem tried to do that -- it did not use DNF lenses and it could not
synthesize anything beyond simple microbenchmarks.  Moreover, this initial
implementation did not even try to search for programs that might use
composition (a second issue our revised system overcomes)!  The priority
queue and ranking system were also motivated by failures endured by earlier
implementations, which were able to synthesize complicated lenses when the
source and target formats were similar, but not when the formats differed
significantly.

BIJECTIVE LENS RESTRICTION

Bijective lenses are a subset of Boomerang's language of lenses, but they
are an important subset that both admits many useful transformations and
also presents some of the crucial technical challenges.  In particular,
overcoming the difficulties introduced by regular expression typing is a
fundamental challenge that is useful for synthesizing larger subsets of
Boomerang and any language related to Boomerang.  We also hope many of the
principles introduced here will apply to languages such as XDuce and other
DTD or XML translation languages, whose schemas are based on upon regular
expressions.

===========================================================================
===========================================================================
The remainder of this document -- to be read only as needed -- responds in
detail to individual concerns not already addressed.

==========================
Review A:
==========================

- The search algorithm, particularly RigidSynth, is described almost
completely in prose, rather than with inductively defined rules.

As mentioned above, we have formalized this as a collection of
inference rules.  We regrettably omitted it for space reasons from
the conference submission.  We can include it in a future version.

- The synthesized lenses are not shown or discussed in much detail,
  nor are they compared to hand-written ones (when possible).  How do
  these compare to hand-written types/terms in Augeas? How do the
  inferred lenses compare to hand-written terms in Augeas (or Flash
  Fill, when appropriate)?

Our implementation puts some work into making the synthesized lenses
readable.  We perform the following transformations (among others):

1. Trivial sublenses are removed
2. Sublenses expressing identity transformations are turned into identities
3. Identity transformations are combined when possible
4. Distributed transformations are factored when possible

The lens we presented above bibtex_to_endnote_au, is an autogenerated
lens.  Overall, we believe bibtex_to_endnote_au is quite similar to
what would be written in Augeas by hand.  One thing a human might
choose to do is to notice that:

lens_swap (NAME . del ",") (lens_swap WSP NAME)*

appears twice.  One could extract this common subexpression and bind it to a
name.  (We could implement a common sub-expression elimination pass but did 
not do so in the submission.)

- How many of surveyed FlashFill examples were close to bijective? Were there
  only the 3 included in the evaluation?

Few of the surveyed FlashFill examples were "close to" bijective.  Most of
them are projections.  Bijections are typically used to synchronize two
data sources in different formats.  Hence the domains are different.  Our
purpose in considering the FlashFill examples was to illustrate that our
tool could handle the bijective data that FlashFill could handle.  And
as we mentioned earlier, there are many formats that we can handle that
FlashFill cannot.

- What do the type specifications look like?

Please scroll down to reviewer D (or grep for "cust/bib_prob" or
"aug/cron" below).  You will see that the formats we are describing
are really quite complicated.  Again, we would like to emphasize the
tradeoff we are studying vs a tool like FlashFill: we ask users to
supply information of kind they are familiar with (regular
expressions), which does clearly take work.  However, the payback is
that we now have a lot of leverage unavailable to other tools, and as
result, makes it possible for us to synthesize transformations over
very complex formats (with many nested iterations and unions that
other tools cannot handle).

- Is there reason to believe that the approach will or will not be
amenable for larger subsets of Boomerang?"  

All of Boomerang is oriented around regular expression typing.
Showing how to manage the core problem of regular expression typing
and equivalence appears to be a crucial first step that any subsequent
tool will need to build on.  We are optimistic this foundation will
support larger subsets of Boomerang.

==========================
Review B:
==========================

- I am not sure the remark about the implementation spanning '5515 lines' is as
positive as you make it sound at the beginning of Section 6. There is no
pseudocode for the main part of the algorithm, a function called RigidSynth.
This makes one wonder how complex it really is and, more worryingly, as a
result, there is also no correctness proof and no complexity analysis.

We regrettably omitted a formalization from the paper for space
reasons.  If authors are given additional pages in a final version of
the paper, we can include a version.  Much of the code is not for the
core synthesis algorithm, but for language transformations, pretty
printing, lens simplification, and DFA operations.  The portion of our
code corresponding to RigidSynth is just over 400 lines.

- some proofs are missing

Please refer to our appendix, where we go into a detailed proof of these
theorems.  (The appendix was submitted with the paper as auxiliary materials ---
please ask other reviewers or the program chair if you have difficulty
locating the auxiliary files on hotcrp.)


==========================
Review D:
==========================

- The algorithmic contributions (particularly, type-directedness) are often
  unclear.

The key algorithmic contribution is our technique for reducing the
language of general lenses to the language of DNF lenses.  We give
a formal completeness argument for this reduction.  

After this reduction, our algorithm is has two phases, which alternate.
One phase rewrites regular expressions according to our rules.  It is
not type directed.  The second phase is type directed:  it is a
divide-and-conquer algorithm that makes a different decision based on
whether the top level constructor is concatenation, union or kleene star.

- Converting a regular expression to DNF may incur an exponential explosion
(as it is akin to determinizing an NFM). Have you encountered examples where
that is the case? Please state this shortcoming.

We have not encountered any examples in practice where this is a problem.
However, we include in our benchmarks cust/cap-prob and cust/2-cap-prob to
highlight this shortcoming.  Furthermore, we discuss the shortcoming in
Speed of Synthesis in the evaluation section.


- Have you considered using a SAT/SMT solver to search the space of
  permutations?

Because of our use of orderings, we are able to find the permutations in
O(n*log(n)) time.  It does not seem likely that a SAT solver would help
here.

- The experimental evaluation is limited and does not back the claimed
  contributions.  Similar to (a), what is the effect of type-directedness on
  the experimental results?

Please see the introductory part of this rebuttal.

- The fact that the avg # of examples is often 0 seems to indicate that the
  benchmarks are simple. This is perhaps because the language is very
  restricted; i.e., there are no user-defined lenses, only the core
  ones. Could you comment on that?

We discuss why the average number of examples is so low in Importance of
Examples in the evaluation section.  To highlight how complicated the input
specifications can be, the specification for the BibTeX to EndNote
conversion problem - one of our 10 least complex input formats - and the
specification for cron - our most complex format - are given below.  We are
happy to provide all our specifications.

cust/bib_prob
      #use "base.decls"
      typedef NAME = UPPERCASE (LOWERCASE)*;;
      
      typedef LASTCOMMASTART = NAME "," (WSP NAME)*;;
      
      typedef STARTTOEND = (NAME WSP)* NAME;;
      
      typedef BIBTEXAUTHORLIST = LASTCOMMASTART (" and " LASTCOMMASTART)*;;
      typedef BIBTEXAUTHORINFO = "author={" BIBTEXAUTHORLIST "}";;
      
      typedef AUTAG = "au - ";;
      typedef TITAG = "ti - ";;
      typedef JOTAG = "jo - ";;
      
      typedef TAGGEDAUTHORDEFNS = AUTAG STARTTOEND ("\n " AUTAG STARTTOEND)*;;
      
      typedef TITLE = NAME (WSP NAME)*;;
      typedef BIBTEXTITLE = "title={" TITLE "}";;
      typedef TAGGEDTITLE = TITAG TITLE;;
      
      typedef JOURNAL = NAME (WSP NAME)*;;
      typedef BIBTEXJOURNAL = "journal={" JOURNAL "}";;
      typedef TAGGEDJOURNAL = JOTAG JOURNAL;;
      
      typedef FULLBIBTEX = "{" ((BIBTEXJOURNAL | BIBTEXAUTHORINFO | BIBTEXTITLE)",")* "}";;
      typedef FULLTAGS = . | ((TAGGEDAUTHORDEFNS | TAGGEDTITLE | TAGGEDJOURNAL)
      (("\n" (TAGGEDAUTHORDEFNS | TAGGEDTITLE | TAGGEDJOURNAL))*)) ;;
      
      bibtex_to_readable_au = [BIBTEXAUTHORINFO <=> TAGGEDAUTHORDEFNS
      {"author={Foster, Nathan and Pierce, Benjamin and Bohannon, Aaron}" <->
      "au - Nathan Foster
       au - Benjamin Pierce
       au - Aaron Bohannon"}]
      
      bibtext_to_readable_title = [BIBTEXTITLE <=> TAGGEDTITLE
      {"title={Boomerang Resourceful Lenses For String Data}" <->
       "ti - Boomerang Resourceful Lenses For String Data"}]
      
      journal_to_readable_journal = [BIBTEXJOURNAL <=> TAGGEDJOURNAL
      {"journal={Principals Of Programming Languages}" <->
       "jo - Principals Of Programming Languages"}]
      
      bibtext_to_tagged_tester= [FULLBIBTEX <=> FULLTAGS {
      "{author={Foster, Nathan and Pierce, Benjamin and Bohannon, Aaron},title={Boomerang Resourceful Lenses For String Data},journal={Principals Of Programming Languages},}"
      <->
      "au - Nathan Foster
       au - Benjamin Pierce
       au - Aaron Bohannon
      ti - Boomerang Resourceful Lenses For String Data
      jo - Principals Of Programming Languages"
      }]
      
      test bibtext_to_tagged_tester
      {"{author={Foster, Nathan and Pierce, Benjamin and Bohannon, Aaron},}"
      <->
      "au - Nathan Foster
       au - Benjamin Pierce
       au - Aaron Bohannon",
      
      "{title={Boomerang Resourceful Lenses For String Data},}"
      <->
      "ti - Boomerang Resourceful Lenses For String Data",
      
      "{journal={Principals Of Programming Languages},}"
      <->
      "jo - Principals Of Programming Languages"
      };;

aug/cron
      #use "base.decls"
      #use "util.decls"
      
      typedef INDENT = (" " | "\t")*;;
      typedef INDENT_REQ = (" " | "\t")+;;
      typedef ALPHANUM = (UPPERCASE | LOWERCASE | DIGIT)+;;
      typedef RANGE = (ALPHANUM "-" ALPHANUM | ALPHANUM );;
      typedef PREFIX = "-";;
      
      typedef SCHEDULE_VALUE = "reboot" | "yearly" | "annually" | "monthly"
                             | "weekly" | "daily" | "midnight" | "hourly";;
      typedef SCHEDULE = "@" SCHEDULE_VALUE;;
      
      typedef USER = (UPPERCASE | LOWERCASE | DIGIT)+;;
      
      typedef TIME = NUMBER INDENT_REQ NUMBER INDENT_REQ NUMBER INDENT_REQ RANGE INDENT_REQ RANGE;;
      
      typedef SHELLCOMMAND_CHAR = LOWERCASE | UPPERCASE | DIGIT | "_" | "/" | "|"  | "." ;;
      typedef SC_CHAR_OR_SPACE = LOWERCASE | UPPERCASE | DIGIT | "_" | "/" | "|" | "." | " " ;;
      typedef SHELLCOMMAND = (SHELLCOMMAND_CHAR (SC_CHAR_OR_SPACE)* SHELLCOMMAND_CHAR) | SHELLCOMMAND_CHAR;;
      
      typedef SHELLVAR_CHAR = LOWERCASE | UPPERCASE | DIGIT | "_";; 
      typedef SHELLVAR_NAME = SHELLVAR_CHAR+;;
      typedef SHELLVALUE_CHAR = LOWERCASE | UPPERCASE | DIGIT | "_" | "/" | "|" | ".";;
      typedef SHELLVALUE_NAME = SHELLVALUE_CHAR+;;
      
      typedef SHELLVAR = SHELLVAR_NAME "=" SHELLVALUE_NAME "\n";;
      typedef COMMENTLINE = COMMENT "\n";;
      typedef ENTRY = INDENT (PREFIX | . ) (TIME | SCHEDULE) INDENT_REQ USER INDENT_REQ SHELLCOMMAND "\n";;
      typedef CRON = ( "\n" | SHELLVAR | COMMENTLINE | ENTRY)*;;
      
      typedef PREFIX_DICT = "{\"prefix\"=" ("true" | "false") "}";;
      typedef TIME_DICT = "{\"minute\"=" NUMBER ",\"ws1\"=" INDENT_REQ ",\"hour\"=" NUMBER 
        ",\"ws2\"=" INDENT_REQ ",\"dayofmonth\"=" NUMBER ",\"ws3\"=" INDENT_REQ 
        ",\"month\"=" RANGE ",\"ws4\"=" INDENT_REQ ",\"dayofweek\"=" RANGE "}";;
      typedef SCHEDULE_DICT = "{\"schedule\"=\"" SCHEDULE_VALUE "\"}";;
      typedef ENTRY_DICT = "{\"indent\"=\"" INDENT "\"," PREFIX_DICT "," (TIME_DICT | SCHEDULE_DICT)
        ",\"indent2\"=\"" INDENT_REQ "\",\"user\"=\"" USER "\",\"indent3\"=\""
        INDENT_REQ "\",\"command\"=\"" SHELLCOMMAND "\"}";;
      typedef SHELL_DICT = "{\"varname\"=\"" SHELLVAR_NAME "\",\"value\"=\"" SHELLVALUE_NAME "\"}";;
      typedef CRON_DICT = ((EMPTYDICT | SHELL_DICT | COMMENT_DICT | ENTRY_DICT) "\n")*;;
      
      cron_lens = [CRON_DICT <=> CRON {}]


==========================
Review E:
==========================

- Why canâ€™t the user provide regular expressions in first place that 
are aligned? 

Describing a single format using a regular expression is a standard
task that programmers understand.  Aligning two regular expressions
is a level more difficult.  Because there are translations going on,
figuring out what needs to be aligned with what does not seem so easy.
Consider the two regular expressions (A|B)C* and
(A|C(C*)A)|(B|B(C*)C).  We believe it is quite 
nontrivial for a user to identify that
the equivalences that must be applied to reach two well aligned
lenses.  Furthermore, the aligned regular expressions could become
difficult to read and maintain: (A|B)(e+C+CC*C) is less understandable
than (A|B)C*.  Surely, avoiding this complexity is a win for the user.
Fortunately, we are successful in our efforts to do alignment
automatically so we can relieve programmers of this burden.

- Is there a restriction that the user-provided regular expressions need to
  parse the source and target formats unambiguously? For example, if a user
  provides the regular expression for a format as Name* Name*, and the input is
  John Conway, would the system disallow such user inputs?

In general, the regular expressions need to be unambiguous.  If they
aren't then the kind of "round tripping" laws one would want simply
won't hold -- i.e. when you translate back-and-forth, you may wind up
corrupting the data.  (And making standard assumptions, like longest
prefix match does not work either).  Nate Foster covers this in depth
in his thesis.  Having said that, there are some places that ambiguity
is allowed.  In our system, we allow users to write ambiguous regular
expressions if they only want to perform the identity transformation
on that part of the string.  (If they want to carve up and rearrange
the data, the disambiguity constraints are important.)

- The synthesis algorithm section presents several heuristics to assign scores
  and pseudometric scores to a pair of DNF regular expressions. How were these
  heuristics chosen? What is the effect of these heuristics on the benchmark
  problems?

Discussed above in the general section. 


==========================
Review F:
==========================

- The examples from FlashFill and are those that can already be synthesized 
  using FlashFill by just providing input / output examples. Also, can the 
  authors describe how complex are the regular expressions that users need 
  to provide? 

Please grep above for "aug/cron" and "cust/bib_prob" to see some example 
specs.

The purpose of the FlashFill examples was just to illustrate that our
system, with the extra information we supply it, certainly has no
problem with the FlashFill examples that are bijective.  As mentioned
above, most of the other benchmarks cannot be handled by FlashFill
because they contain nested iterations.  In total, 17 of the examples
contain nested iterations.  The most complex have 4 levels of nested
iterations.  These examples cannot be handled by FlashFill.

- Given that the same data format can be
  described using different semantically equivalent expressions, how do they
  affect the effectiveness of the synthesis process?

As we discuss in Speed of Synthesis, in the Evaluation section, the
difference in the presentation of the regular expressions can have an
impact on the performance of synthesis.  The "farther away" the two
pairs of expressions are, the more search is needed to find
sufficiently compatible pairs of regular expressions.  Much of the
focus of our heuristics is on identifying compatible regular
expression pairs during search.  Our experiments suggest they are
successful.

- Finally, the real world contains many erroneous / dirty data. What happens if
  the user provide the incorrect regular expression or inconsistent input /
  output examples?

Briefly, one can test the regular expression against available data to
see if it parses the available data, but we offer no special support
here --- doing so is beyond the scope of this paper. Our experiments
suggest we need very few examples -- often zero or one.  If in the one
example the user puts the data in the wrong place, the user will
simply have specified the wrong transformation.  Developing some more
general machinery for analyzing many examples, some of which may be
noisy/buggy, is beyond the scope of this paper.

- Can the authors describe what kind of examples were needed to
  achieve the efficient synthesis results? In light of the "Importance of
  Examples" subsection on p.11, it seems that choosing "clever" examples is one
  of the key requirement for the tool to succeed in synthesizing a valid
  program.

"Clever" examples do not need to be provided to the system.  The "Avg # Exmpl"
column gets its value from randomly generated examples.

- What happens if multiple lens program are found for a given input?

The system returns the "simplest" program (using a heuristic notion of
"simplest").
